{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#机器学习包\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import make_scorer, explained_variance_score, median_absolute_error\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVR \n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "import time\n",
    "\n",
    "#神经网络包\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset,TensorDataset,DataLoader\n",
    "from torch.utils.data import random_split\n",
    "import matplotlib.pyplot as plt\n",
    "import random, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#保证数据可复现\n",
    "#设置全局随机种子，以确保代码运行时的随机性得到控制，从而保证数据可复现性\n",
    "def random_seed(seed):\n",
    "      # 控制 Python 内置的随机数生成器\n",
    "    random.seed(seed)\n",
    "\n",
    "    # 控制 Python 内部的哈希函数随机化，以确保字符串的哈希值是可复现的\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "    # 控制 NumPy 的随机数生成器\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # 控制 PyTorch 的 CPU 随机数生成器\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    # 控制 PyTorch 在使用单个 GPU 时的随机性\n",
    "    torch.cuda.manual_seed(seed)\n",
    "\n",
    "    # 控制 PyTorch 在使用多个 GPU 时的随机性\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "    # 确保 PyTorch 的计算是确定性的，禁用某些非确定性算法\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "#自定义函数\n",
    "#定义函数\n",
    "#标准化数据\n",
    "#这个函数用于对特征数据进行标准化处理\n",
    "#（即将数据转换为均值为 0、方差为 1 的标准正态分布），并返回标准化后的数据和标签的组合。\n",
    "def ss(features, labels):\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    scaler = StandardScaler()   # 使用标准化工具\n",
    "    X_s = scaler.fit_transform(features)  # 对特征进行标准化\n",
    "    X_s = pd.DataFrame(X_s)  # 转换为 DataFrame\n",
    "    data = pd.concat([X_s, labels], axis=1)  # 将标准化后的特征与标签拼接\n",
    "    return data\n",
    "\n",
    "# MAPE 计算函数\n",
    "def mape_scorer(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "\n",
    "def model_score(model, x, y, trainsize, testsize):\n",
    "    # 创建交叉验证生成器\n",
    "    cv = ShuffleSplit(n_splits=10, train_size=trainsize, test_size=testsize, random_state=0)\n",
    "\n",
    "    # 计算 RMSE\n",
    "    rmse = cross_val_score(model, x, y, scoring=\"neg_mean_squared_error\", cv=cv)\n",
    "    rmse_score = np.sqrt(-rmse)\n",
    "    rmse_mean = rmse_score.mean()\n",
    "\n",
    "    # 计算 MAE\n",
    "    mae = cross_val_score(model, x, y, scoring=\"neg_mean_absolute_error\", cv=cv)\n",
    "    mae_score = -mae\n",
    "    mae_mean = mae_score.mean()\n",
    "\n",
    "    # 计算 R²\n",
    "    r2 = cross_val_score(model, x, y, scoring='r2', cv=cv)\n",
    "    r2_mean = r2.mean()\n",
    "\n",
    "    # 计算 MAPE\n",
    "    mape = cross_val_score(model, x, y, scoring=make_scorer(mape_scorer, greater_is_better=False), cv=cv)\n",
    "    mape_score = -mape\n",
    "    mape_mean = mape_score.mean()\n",
    "\n",
    "    # 计算 MedAE\n",
    "    medae = cross_val_score(model, x, y, scoring=make_scorer(median_absolute_error, greater_is_better=False), cv=cv)\n",
    "    medae_score = -medae\n",
    "    medae_mean = medae_score.mean()\n",
    "\n",
    "    # 将所有评分结果整合\n",
    "    scores = [\n",
    "        rmse_score, rmse_mean, mae_score, mae_mean, r2, r2_mean, mape_score, mape_mean, medae_score, medae_mean]\n",
    "    \n",
    "    # 创建各指标的 DataFrame\n",
    "    rmse_df = pd.DataFrame(scores[0], columns=['rmse'], index=np.arange(len(scores[0])))\n",
    "    mae_df = pd.DataFrame(scores[2], columns=['mae'], index=np.arange(len(scores[2])))\n",
    "    r2_df = pd.DataFrame(scores[4], columns=['r2'], index=np.arange(len(scores[4])))\n",
    "    mape_df = pd.DataFrame(scores[6], columns=['mape'], index=np.arange(len(scores[6])))\n",
    "    medae_df = pd.DataFrame(scores[8], columns=['medae'], index=np.arange(len(scores[8])))\n",
    "\n",
    "    # 合并所有得分结果\n",
    "    scores_df = pd.concat([rmse_df, mae_df, r2_df, mape_df, medae_df], axis=1)\n",
    "\n",
    "    return scores_df\n",
    "\n",
    "\n",
    "\n",
    "#导出预测值到csv\n",
    "#此函数将真实值和预测值写入到 CSV 文件中。\n",
    "def ToCsv(model, Xtest, ytest, filename):\n",
    "    ytest = pd.DataFrame(ytest.values, index=[np.arange(len(ytest))], columns=['yreal1', 'yreal2', 'yreal3'])\n",
    "    ypredict = model.predict(Xtest)\n",
    "    ypredict = pd.DataFrame(ypredict, index=[np.arange(len(ytest))], columns=['ypredict1', 'ypredict2', 'ypredict3'])\n",
    "    # ypredict\n",
    "    # 合并真实值和预测值\n",
    "    output = pd.concat([ytest, ypredict], axis=1)\n",
    "    output.to_csv(filename)\n",
    "\n",
    "#数据导入＋预处理\n",
    "#此函数从 CSV 文件读取数据，并对其进行标准化处理，最后返回特征和标签\n",
    "def DataProcess(path):\n",
    "    data = pd.read_csv(path)\n",
    "    data_df = pd.DataFrame(data)\n",
    "    # 提取特征和标签\n",
    "    X = data_df.iloc[:,1:6]\n",
    "    y = data_df.iloc[:,6:9]\n",
    "    # # 标准化处理\n",
    "    # data_s = ss(X_df,y_df)\n",
    "    # X = data_df.iloc[:,0:5]\n",
    "    # y = data_df.iloc[:,5:]\n",
    "    return X, y\n",
    "\n",
    "def DataProcess1(path):\n",
    "    data = pd.read_csv(path)\n",
    "    data_df = pd.DataFrame(data)\n",
    "    # 提取特征和标签\n",
    "    X_df = data_df.iloc[:,1:6]\n",
    "    y_df = data_df.iloc[:,6:9]\n",
    "    # 标准化处理\n",
    "    data_s = ss(X_df,y_df)\n",
    "    X = data_s.iloc[:,0:5]\n",
    "    y = data_s.iloc[:,5:]\n",
    "    return X, y\n",
    "\n",
    "#数据集拆分\n",
    "def DataSplit(X, y, trainsize, testsize):\n",
    "    # 计算训练集的样本数量\n",
    "    n_train = int(len(X) * trainsize)\n",
    "    \n",
    "    # 将前面部分作为训练集，后面部分作为测试集\n",
    "    Xtrain, Xtest = X.iloc[:n_train], X.iloc[n_train:]\n",
    "    ytrain, ytest = y.iloc[:n_train], y.iloc[n_train:]\n",
    "    \n",
    "    return Xtrain, Xtest, ytrain, ytest\n",
    "\n",
    "#此函数将特征和标签数据集进行训练集和测试集的划分，并使用固定的随机种子来保证可复现性。\n",
    "def DataSplit1(X,y, testsize, seed):\n",
    "    random_seed(seed)\n",
    "    Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=testsize)\n",
    "    return Xtrain, Xtest, ytrain, ytest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DNN模型、函数\n",
    "\n",
    "#神经网络数据处理三步：\n",
    "#1.加载数据，提取出feature和label，并转换成tensor\n",
    "#2.传入TensorDataset中，实例化TensorDataset为datsset\n",
    "#3.再将dataset传入到Dataloader中，最后通过enumerate输出我们想要的经过shuffle的bachsize大小的feature和label数据\n",
    "'''数据预处理'''\n",
    "#dataframe转换为tensor\n",
    "#将DataFrame数据转换为PyTorch张量。\n",
    "def Df2Tensor(df):\n",
    "    array = np.array(df)\n",
    "    tensor = torch.tensor(array, dtype=torch.float32)\n",
    "    return tensor\n",
    "#将张量打包成TensorDataset，供模型使用。\n",
    "def ToDataset(*args):\n",
    "    return TensorDataset(*args)\n",
    "\n",
    "#dataset变迭代器\n",
    "#将数据集转为可迭代的DataLoader，方便进行批量训练。\n",
    "def ToDataLoader(dataset, batchsize):\n",
    "    return DataLoader(dataset, batchsize, shuffle=True)\n",
    "\n",
    "\n",
    "'''定义网络结构'''\n",
    "#Net类定义了一个拥有四层隐藏层的神经网络，并在每一层之间应用了Dropout正则化。ReLU函数用于激活。\n",
    "#nn.Linear（全连接层）、激活函数如ReLU、Sigmoid，以及正则化层如Dropout\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, \n",
    "            input_dim, output_dim, \n",
    "            hidden_layer1, hidden_layer2, hidden_layer3, hidden_layer4, \n",
    "            dropout1, dropout2, dropout3, dropout4):\n",
    "        super(Net, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_dim,hidden_layer1)\n",
    "        self.layer2 = nn.Linear(hidden_layer1,hidden_layer2)\n",
    "        self.layer3 = nn.Linear(hidden_layer2,hidden_layer3)\n",
    "        self.layer4 = nn.Linear(hidden_layer3,hidden_layer4)\n",
    "        self.layer5 = nn.Linear(hidden_layer4,output_dim)\n",
    "\n",
    "        self.dropout1 = nn.Dropout(dropout1)\n",
    "        self.dropout2 = nn.Dropout(dropout2)\n",
    "        self.dropout3 = nn.Dropout(dropout3)\n",
    "        self.dropout4 = nn.Dropout(dropout4)\n",
    "\n",
    "        # self.relu = nn.ReLU()\n",
    "#前向传播：输入数据经过模型进行前向计算，输出预测值。\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout1(x)\n",
    "\n",
    "        x = self.layer2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "\n",
    "        x = self.layer3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout3(x)\n",
    "\n",
    "        x = self.layer4(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout4(x)\n",
    "\n",
    "        x = self.layer5(x)\n",
    "        return x\n",
    "\n",
    "'''训练与评估'''\n",
    " #定义模型评估参数\n",
    " #Metrics类：定义了常见的评估指标，包括rmse（均方根误差）、mae（平均绝对误差）和r2（R²决定系数）\n",
    "class Metrics:\n",
    "    def __init__(self, net, dataloader):\n",
    "        dataset = dataloader.dataset\n",
    "        self.features = dataset[:][0]\n",
    "        self.labels = dataset[:][1]\n",
    "        # 将预测值限定在 1 到正无穷之间，以避免取对数时出现负值\n",
    "        self.y_hat = torch.clamp(net(self.features), 1, float('inf'))\n",
    "    \n",
    "    def rmse(self):\n",
    "        \"\"\"计算 RMSE\"\"\"\n",
    "        return torch.sqrt(F.mse_loss(self.y_hat, self.labels))\n",
    "    \n",
    "    def mae(self):\n",
    "        \"\"\"计算 MAE\"\"\"\n",
    "        return F.l1_loss(self.y_hat, self.labels)\n",
    "    \n",
    "    def smooth_mae(self):\n",
    "        \"\"\"计算 Smooth L1 Loss (平滑 MAE)\"\"\"\n",
    "        return F.smooth_l1_loss(self.y_hat, self.labels)\n",
    "    \n",
    "    def r2(self):\n",
    "        \"\"\"计算 R² (决定系数)\"\"\"\n",
    "        SS_res = torch.sum(torch.square(self.labels - self.y_hat))\n",
    "        SS_tot = torch.sum(torch.square(self.labels - torch.mean(self.labels)))\n",
    "        r2 = 1 - SS_res / SS_tot\n",
    "        return r2\n",
    "    \n",
    "    def mape(self):\n",
    "        \"\"\"计算 MAPE (平均绝对百分比误差)\"\"\"\n",
    "        return torch.mean(torch.abs((self.labels - self.y_hat) / self.labels)) * 100\n",
    "    \n",
    "    def medae(self):\n",
    "        \"\"\"计算 MedAE (中位绝对误差)\"\"\"\n",
    "        return torch.median(torch.abs(self.labels - self.y_hat))\n",
    "\n",
    "\n",
    "\n",
    "# #初始化权重\n",
    "def init_weights(m):\n",
    "  if type(m) == nn.Linear:\n",
    "    nn.init.normal_(m.weight, std=0.01)\n",
    "\n",
    "#数据集特征与标签合并\n",
    "def DataConcat(Xtrain, Xtest, ytrain, ytest):\n",
    "    train_df = [Xtrain, ytrain]\n",
    "    test_df = [Xtest, ytest]\n",
    "    train_data = pd.concat(train_df,axis=1)\n",
    "    test_data = pd.concat(test_df,axis=1)\n",
    "    return train_data, test_data\n",
    "\n",
    "#定义训练函数,用Adam优化器训练\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "#train：使用Adam优化器训练模型，并引入了学习率调度器StepLR，控制学习率逐渐衰减\n",
    "\n",
    "#前向传播：输入数据经过模型进行前向计算，输出预测值。\n",
    "#计算损失：将预测值与真实标签计算损失值。\n",
    "#反向传播：通过loss.backward()计算梯度。\n",
    "#优化更新：调用optimizer.step()更新模型参数，之后用optimizer.zero_grad()清空梯度。\n",
    "#重复以上步骤：遍历整个数据集若干次（称为epoch），逐步优化模型。\n",
    "def train(net, dataloader, loss, num_epochs, lr, wd):\n",
    "    net.train()\n",
    "    \n",
    "    #train_data[:][0]可以获取train_data中的特征，[1]获取标签\n",
    "\n",
    "    # 这里使用的是Adam优化算法\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr = lr, weight_decay = wd)\n",
    "    #每隔一个step_size,学习率乘以gamma\n",
    "    scheduler = StepLR(optimizer, step_size=num_epochs/3, gamma=0.3)\n",
    "#遍历整个数据集若干次（称为epoch)\n",
    "    for epoch in range(num_epochs):\n",
    "        for X, y in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            l = loss(net(X), y) \n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # with torch.no_grad():\n",
    "            #     print(l)\n",
    "\n",
    "#模型评估\n",
    "def NetEval(net, dataloader, num_epochs, loss, lr, wd):\n",
    "    # 模型评估指标矩阵\n",
    "    rmse, mae, r2, mape, medae = [], [], [], [], []\n",
    "\n",
    "    # 模型训练过程\n",
    "    for epoch in range(num_epochs):\n",
    "        net.train()\n",
    "        train(net, dataloader, loss, num_epochs, lr, wd)\n",
    "\n",
    "        net.eval()\n",
    "        test_metrics = Metrics(net, dataloader)\n",
    "\n",
    "        # 计算各项指标并存储\n",
    "        rmse.append(test_metrics.rmse().detach().item())\n",
    "        mae.append(test_metrics.mae().detach().item())\n",
    "        r2.append(test_metrics.r2().detach().item())\n",
    "        mape.append(test_metrics.mape().detach().item())  # 计算 MAPE\n",
    "        medae.append(test_metrics.medae().detach().item())  # 计算 MedAE\n",
    "\n",
    "    # 返回各项指标\n",
    "    return r2, mae, rmse, mape, medae\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集特征 (Xtrain):\n",
      "    槽开口宽度Bs0（mm）  永磁体轴向长度/动子极距            a  气隙厚度gap（mm）  线圈径向宽度rcoil（mm）  \\\n",
      "0       0.709952                   0.447214     1.341641         1.224745   \n",
      "1       0.709952                  -0.447214    -1.341641         1.224745   \n",
      "2       0.709952                   0.447214    -1.341641         1.224745   \n",
      "3       0.709952                   1.341641     1.341641        -1.224745   \n",
      "4       0.709952                   0.447214    -1.341641        -1.224745   \n",
      "..           ...                        ...          ...              ...   \n",
      "67      0.283981                   0.447214    -1.341641         1.224745   \n",
      "68      0.709952                   0.447214     1.341641        -1.224745   \n",
      "69      0.709952                  -0.447214    -1.341641         1.224745   \n",
      "70      0.283981                   0.447214     1.341641         1.224745   \n",
      "71      0.283981                   0.447214     1.341641        -1.224745   \n",
      "\n",
      "    永磁体径向长度rpm（mm）  \n",
      "0          0.29277  \n",
      "1         -0.87831  \n",
      "2         -0.87831  \n",
      "3          0.87831  \n",
      "4         -1.46385  \n",
      "..             ...  \n",
      "67         1.46385  \n",
      "68         0.87831  \n",
      "69        -0.29277  \n",
      "70        -1.46385  \n",
      "71        -0.29277  \n",
      "\n",
      "[72 rows x 5 columns]\n",
      "\n",
      "训练集标签 (ytrain):\n",
      "       平均推力（N）    推力波动（N）    平均铜损(W)\n",
      "0   102.875961  46.711569  24.319113\n",
      "1    87.437076  39.778524  22.802622\n",
      "2    91.887490  62.385267  22.802622\n",
      "3    99.463297  49.278669  19.051266\n",
      "4    68.203225  38.544622  17.154676\n",
      "..         ...        ...        ...\n",
      "67  127.466699  95.599635  24.535495\n",
      "68   93.418125  31.352949  19.051266\n",
      "69   97.579738  41.112232  23.236249\n",
      "70   75.807890  28.079051  23.019472\n",
      "71   73.212626  33.367646  18.362132\n",
      "\n",
      "[72 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# 数据集预处理\n",
    "Path = \"FEA——train0.1.csv\"\n",
    "\n",
    "seed = 0\n",
    "trainsize, testsize = 0.1, 0.9\n",
    "\n",
    "\n",
    "# 加载并划分数据集\n",
    "X, y = DataProcess(Path)\n",
    "Xtrain, Xtest, ytrain, ytest = DataSplit(X, y, trainsize, testsize)\n",
    "\n",
    "# 打印训练集的 X 和 y\n",
    "print(\"训练集特征 (Xtrain):\")\n",
    "print(Xtrain)\n",
    "print(\"\\n训练集标签 (ytrain):\")\n",
    "print(ytrain)\n",
    "\n",
    "# 数据预处理\n",
    "# 将 tensor 转化为 dataset 对象\n",
    "train_dataset = ToDataset(Df2Tensor(Xtrain), Df2Tensor(ytrain))\n",
    "test_dataset = ToDataset(Df2Tensor(Xtest), Df2Tensor(ytest))\n",
    "\n",
    "# 设置 batch size\n",
    "batchsize = 54\n",
    "train_dataloader = ToDataLoader(train_dataset, batchsize)\n",
    "test_dataloader = ToDataLoader(test_dataset, batchsize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#导入解析法数据\n",
    "AM_Path = 'AM_data.csv'\n",
    "seed = 0\n",
    "trainsize1, testsize1 = 0.99,0.01\n",
    "X, y = DataProcess1(AM_Path)\n",
    "Xtrain1, Xtest1, ytrain1, ytest1 = DataSplit1(X,y, testsize1, seed)\n",
    "\n",
    "#数据预处理\n",
    "# Xtrain, Xtest, ytrain, ytest\n",
    "#将tensor转化为dataset对象\n",
    "train_dataset1 = ToDataset(Df2Tensor(Xtrain1), Df2Tensor(ytrain1))\n",
    "test_dataset1 = ToDataset(Df2Tensor(Xtest1), Df2Tensor(ytest1))\n",
    "\n",
    "batchsize = 54\n",
    "train_dataloader1 = ToDataLoader(train_dataset1, batchsize)\n",
    "test_dataloader1= ToDataLoader(test_dataset1, batchsize)\n",
    "\n",
    "# for i,d in enumerate(train_dataloader):\n",
    "#     X,y = d\n",
    "#     print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (layer1): Linear(in_features=5, out_features=120, bias=True)\n",
       "  (layer2): Linear(in_features=120, out_features=60, bias=True)\n",
       "  (layer3): Linear(in_features=60, out_features=30, bias=True)\n",
       "  (layer4): Linear(in_features=30, out_features=15, bias=True)\n",
       "  (layer5): Linear(in_features=15, out_features=3, bias=True)\n",
       "  (dropout1): Dropout(p=0, inplace=False)\n",
       "  (dropout2): Dropout(p=0.01, inplace=False)\n",
       "  (dropout3): Dropout(p=0.01, inplace=False)\n",
       "  (dropout4): Dropout(p=0.01, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#定义超参数与网络\n",
    "input_dim, output_dim, hidden_layer1, hidden_layer2, hidden_layer3, hidden_layer4 = 5, 3, 120,60,30,15\n",
    "# num_epochs, lr, weight_decay, batch_size = 3000, 0.01, 0.002, 54\n",
    "num_epochs, lr, wd, batch_size = 1000, 0.003, 0, 54\n",
    "dropout1, dropout2, dropout3, dropout4 = 0,0.01,0.01,0.01\n",
    "\n",
    "loss = nn.MSELoss()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "net = Net(input_dim, output_dim, \n",
    "            hidden_layer1, hidden_layer2, hidden_layer3, hidden_layer4,\n",
    "            dropout1, dropout2, dropout3, dropout4)\n",
    "net.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#解析法数据训练网络\n",
    "train(net, train_dataloader1, loss, num_epochs, lr, wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "##FEA数据训练网络\n",
    "train(net, train_dataloader, loss, num_epochs, lr, wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DTNN 模型的评估结果：\n",
      "DTNN_R²: 0.9904209494590759\n",
      "DTNN_MAE: 2.1184255599975588\n",
      "DTNN_RMSE: 3.095784401893616\n",
      "DTNN_MAPE: 4.857172727584839\n",
      "DTNN_MedAE: 1.2506858825683593\n"
     ]
    }
   ],
   "source": [
    "# 模型评估\n",
    "eval_epochs = 10\n",
    "wd = 0\n",
    "r2, mae, rmse, mape, medae = NetEval(net, test_dataloader, eval_epochs, loss, lr, wd)\n",
    "\n",
    "eval_epochs = 10\n",
    "lr1 = lr/2\n",
    "r2, mae, rmse, mape, medae = NetEval(net, test_dataloader, eval_epochs, loss, lr1, wd)\n",
    "\n",
    "eval_epochs = 10\n",
    "lr1 = lr/2\n",
    "r2, mae, rmse, mape, medae = NetEval(net, test_dataloader, eval_epochs, loss, lr1, wd)\n",
    "\n",
    "# 计算各个指标的平均值\n",
    "DTNN_R2_mean = np.mean(r2)                               # 平均 R²\n",
    "DTNN_mae_mean = np.mean(mae)                             # 平均 MAE\n",
    "DTNN_rmse_mean = np.mean(rmse)                           # 平均 RMSE\n",
    "DTNN_mape_mean = np.mean(mape)                           # 平均 MAPE\n",
    "DTNN_medae_mean = np.mean(medae)                         # 平均 MedAE\n",
    "\n",
    "# 输出各个指标的平均值\n",
    "print(\"DTNN 模型的评估结果：\")\n",
    "print(f\"DTNN_R²: {DTNN_R2_mean}\")\n",
    "print(f\"DTNN_MAE: {DTNN_mae_mean}\")\n",
    "print(f\"DTNN_RMSE: {DTNN_rmse_mean}\")\n",
    "print(f\"DTNN_MAPE: {DTNN_mape_mean}\")\n",
    "print(f\"DTNN_MedAE: {DTNN_medae_mean}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#保存数据\n",
    "def ToCsv(model, Xtest, ytest, ypredict, filename):\n",
    "    ytest = pd.DataFrame(ytest, index=[np.arange(len(ytest))], columns=['yreal1', 'yreal2', 'yreal3'])\n",
    "\n",
    "    ypredict = pd.DataFrame(ypredict, index=[np.arange(len(ytest))], columns=['ypredict1', 'ypredict2', 'ypredict3'])\n",
    "    # ypredict\n",
    "    output = pd.concat([ytest, ypredict], axis=1)\n",
    "    output.to_csv(filename)\n",
    "    \n",
    "y_predict = net(Df2Tensor(Xtest)).detach().numpy()\n",
    "y_test = Df2Tensor(ytest).detach().numpy()\n",
    "\n",
    "s = './样本挑选-迁移结果汇总/TL——DNN——Picking结果{}-{}.csv'.format(int(trainsize*10), int(testsize*10))\n",
    "ToCsv(net,Xtest,y_test,y_predict,s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "all_evals = [[DTNN_R2_mean, DTNN_mae_mean, DTNN_rmse_mean, DTNN_mape_mean, DTNN_medae_mean]]\n",
    "\n",
    "df = pd.DataFrame(all_evals, columns=[\n",
    "    'R2', 'MAE', 'RMSE', 'MAPE','MEDAE'\n",
    "], index=['DTNN'], dtype=float)\n",
    "\n",
    "df.to_csv(\"./样本挑选-迁移结果汇总/TL——DNN——Picking评估指标汇总ce{}-{}.csv\".format(int(trainsize*10), int(testsize*10)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "XG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
